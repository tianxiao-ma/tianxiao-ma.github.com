---
title: 通过Map-Reduce实现Join系列之三
layout: post
permalink: /2013/01/mapred-3/
date: Sat Jan 19 22:37:00 am GMT+8 2013
published: true
---

在这个系列的[第一篇](/2013/01/mapred-1/)和[第二篇](/2013/01/mapred-2/)，介绍了基本的Join算法以及在Hadoop环境中，如何利用Map-Reduce过程来完成Join。而前面的介绍都是基于两个集合的Join，本文将会介绍利用Map-Reduce来完成2个以上文件的Join的相关算法(Multi-way join algorithms)。基本的思路与第二篇文章中介绍的Map-Reduce Join类似，根据将这个算法扩展到多个文件的方式，可以分为两种，一种是使用一个Map-Reduce任务完成所有文件的Join，另外一个中使用多个任务来完成多个文件的Join。

1. 使用单个Map-Reduce任务完成Join

	这种算法可以看作是第二篇中提到的基于一个完整的Map-Reduce来完成Join的算法的扩展。比如，有n个数据文件需要Join，他们分别是T1(A1,B)，T2(A2,B)，T3(A3,B)，....，Tn(An,B)，需要在B列上进行Join。

	* Map阶段

	Map阶段从每个文件读取数据，然后根据一定的规则为不同来源的数据打上标记，然后以B列的值为Key，将数据写出到中间文件中。

	* Reduce阶段

	所有在B列上具有相同值的来自不同文件的记录会被同一个Reducer进行处理。在第二篇的介绍中，对于两个文件的join，Reducer在调用reduce方法之前，会对同一个key下面的数据进行排序，保证来自于一个文件的所有数据会优先与另外一个文件的数据，对于多个文件的Join，这一点也同样需要得到保证。通过自定义Reducer端的分组和排序方式，可以达到这样的效果。recude方法将同一个key下来自于前n-1个文件的数据全部读到内存缓存起来，当读第n个文件的数据时，开始进行执行join操作，并将结果写出到结果文件中。 

	这种算法的优点在于可以通过一个Map-Reduce任务完成所有数据文件的join，同时，产生的零时文件也是最少的，比较节省HDFS的磁盘空间。但是这个算法存在一个最大的劣势，Reducer阶段需要缓存大量的数据，当需要进行Join的数据文件个数比较多时，很容易产生内存的不足的情况。虽然可以将缓存的数据进行切分，放入磁盘，但是这样做会带来性能上的损失，同时也增加了算法的复杂度。

2. 使用多个Map-Reduce任务完成Join

	除了上面说的将多个文件的Join放到一个Map-Reduce任务中去完成之外，我们还可以将多个文件的Join切分成多个不同的Map-Reduce任务去执行。例如， 有n个数据文件需要Join，他们分别是T1(A1,B)，T2(A2,B)，T3(A3,B)，....，Tn(An,B)，需要在B列上进行Join。我们可以将T1和T2进行Join，然后将其结果与T3进行Join，以此类推，最终完成n个数据文件的Join操作。 

	这种Join方式适用于任何大小任何数据量的文件之间的Join，而且相比于第一种方式，单个Map-Reduce任务需要处理的数据量小了很多。但是，由于需要实用多个Map-Reduce任务来完成Join，这种方式会产生很多的中间文件，占用HDFS的磁盘空间，同时对整个Hadoop集群带来的压力也比第一种方式要高很多。

	* 多任务Join的优化

	简单的每次Join两个数据文件的方式其实是非常低效的，不仅消耗存储资源，对计算资源的消耗也非常巨大，下面有集中方式可以来优化多Map-Reduce任务的Join。

	首先，可以对每个任务产生的中间文件进行压缩处理，这样可以大大减小中间数据对存储的 消耗，同时也可以减小对网络贷款的消耗，因为要传输给Mapper或者Reducer的数据量减小了。 

	第二，可以通过优化数据文件的Join顺序来提高效率。这种优化主要通过衡量两个数据文件Join之后可能产生的数据量来决定各个数据文件的Join顺序。Join之后产生的数据量最小的两个文件将被有限进行Join，以此类推。现在考虑如下的两个数据集合： 
	
	![mapred-img-4](/images/2013-01/hadoop-mapreduce/mapred-img-4.jpg)

	这两个文件Join之后的结果如下： 

	![mapred-img-5](/images/2013-01/hadoop-mapreduce/mapred-img-5.jpg)

	数据的记录数可以通过下面的公式得到：
	
	![mapred-img-6](/images/2013-01/hadoop-mapreduce/mapred-img-6.jpg)

	其中，T(K)表示数据文件T中，Join条件用到的列上，具有K值的记录条数。 

	在上面给出的例子中，通过计算，我们可以得到这两个数据集合Join之后，将会产生的记录数是：

	`1 x 1 + 2 x 1 + 1 x 2 = 5`

	只要我们能够找出每个数据文件中包含的key的数量，已经每个key下面对应的记录的条数，我们可以很容易的决定各个数据文件之间的Join顺序。这个计算我们可以放到一个数据的预处理过程中，然后将预处理的结果存到HDFS上的一个指定文件中，当执行多文件Join时，首先读取这个文件，然后根据文件内容逐个两两Join不同的数据文件。 

	第三，在知道了不同文件Join之后所产生的数据量之后，我们可以在一个Map-Reduce任务中尽量多地Join几个数据文件，而不是每次只Join两个数据文件，这样做也可以起到一定的节省存储和计算资源的效果。

[>>通过Map-Reduce实现Join系列之一](/2013/01/mapred-1/)

[>>通过Map-Reduce实现Join系列之二](/2013/01/mapred-2/)

[>>通过Map-Reduce实现Join系列之三](/2013/01/mapred-3/)

[>>通过Map-Reduce实现Join系列之四](/2013/01/mapred-4/)
